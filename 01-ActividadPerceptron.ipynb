{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad, prediciendo imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta actividad vamos a predecir un set de imagenes que viene precargado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obteniendo el set de datos, 60000 dígitos escritos a mano entre 0 y 9 (incluído)\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 35 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# usando Matplotlib (NO PREGUNTE)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 35  # how many digits we will display\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Transforme cada uno de los datasets a valores del tipo float32 y dividalos por 255 para dejarlos entre 0 y 1\n",
    "#Posteriormente, cambie las dimensiones de los datos para poder entrenar un modelo perceptron (use el método reshape)\n",
    "#Discuta:\n",
    "#¿Cuantas neuronas de entrada deberá tener el perceptron?: \n",
    "#¿Como debería ser la dimensión final de los datos?\n",
    "#¿Cuál debería ser el output final del Perceptron (defina el problema de clasificación)?\n",
    "\n",
    "\"\"\"\n",
    "Respuestas: \n",
    "1. Dado que el input son imágenes de 28*28, entonces debería tener 784. Una por cada píxel.\n",
    "2. Una matriz con 60000 filas, cada fila representa una imágen con sus 784 píxeles.\n",
    "3. Deberían ser la probabilidad de pertenencia al conjunto de números del 0 al 9.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de set de entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  60000 and each image is of shape(784)\n",
      "Number of test examples:  10000 and each image is of shape(784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((60000, 28 * 28))\n",
    "x_test = x_test.reshape((10000, 28 * 28))\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print(\"Number of training examples: \",x_train.shape[0],f\"and each image is of shape({x_train.shape[1]})\")\n",
    "print(\"Number of test examples: \",x_test.shape[0],f\"and each image is of shape({x_test.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label of train first image:  5\n",
      "Class label of test first image:  7\n",
      "After converting the output into a vector :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "After converting the output into a vector :  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "print(\"Class label of train first image: \",y_train[0])\n",
    "print(\"Class label of test first image: \",y_test[0])\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train,10) # one hot encoding\n",
    "y_test = np_utils.to_categorical(y_test,10)  # one hot encoding\n",
    "\n",
    "print(\"After converting the output into a vector : \",y_train[0])\n",
    "#print(\"After converting the output into a vector : \",y_test[0])\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:35:53.016997: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-13 23:35:53.018337: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cree y entrene el modelo perceptron, defina loss y o\n",
    "\n",
    "from tensorflow.keras import *\n",
    "\n",
    "inputLayer = layers.Input(shape=(784,)) #784 neuronas para cada pixel\n",
    "\n",
    "outputLayer = layers.Dense(10,activation='sigmoid',use_bias = True)(inputLayer) # 0,1,...,9 el target a predecir\n",
    "\n",
    "#Connecting the model\n",
    "perceptron = models.Model(inputLayer, outputLayer)\n",
    "perceptron.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:40:53.606048: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-13 23:40:53.612494: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:40:53.856901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 7s 4ms/step - loss: 0.3262 - binary_accuracy: 0.8910\n",
      "Epoch 2/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2338 - binary_accuracy: 0.9124\n",
      "Epoch 3/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1987 - binary_accuracy: 0.9287\n",
      "Epoch 4/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1780 - binary_accuracy: 0.9390\n",
      "Epoch 5/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1642 - binary_accuracy: 0.9452\n",
      "Epoch 6/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1542 - binary_accuracy: 0.9496\n",
      "Epoch 7/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1466 - binary_accuracy: 0.9528\n",
      "Epoch 8/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1406 - binary_accuracy: 0.9553\n",
      "Epoch 9/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1356 - binary_accuracy: 0.9573\n",
      "Epoch 10/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1314 - binary_accuracy: 0.9588\n",
      "Epoch 11/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1279 - binary_accuracy: 0.9601\n",
      "Epoch 12/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1248 - binary_accuracy: 0.9612\n",
      "Epoch 13/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1221 - binary_accuracy: 0.9620\n",
      "Epoch 14/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1197 - binary_accuracy: 0.9629\n",
      "Epoch 15/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1175 - binary_accuracy: 0.9637\n",
      "Epoch 16/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1156 - binary_accuracy: 0.9643\n",
      "Epoch 17/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1139 - binary_accuracy: 0.9649\n",
      "Epoch 18/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1123 - binary_accuracy: 0.9654\n",
      "Epoch 19/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1108 - binary_accuracy: 0.9659\n",
      "Epoch 20/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1095 - binary_accuracy: 0.9663\n",
      "Epoch 21/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1082 - binary_accuracy: 0.9667\n",
      "Epoch 22/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1071 - binary_accuracy: 0.9670\n",
      "Epoch 23/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1060 - binary_accuracy: 0.9673\n",
      "Epoch 24/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1050 - binary_accuracy: 0.9676\n",
      "Epoch 25/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1040 - binary_accuracy: 0.9679\n",
      "Epoch 26/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1032 - binary_accuracy: 0.9682\n",
      "Epoch 27/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1023 - binary_accuracy: 0.9684\n",
      "Epoch 28/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1015 - binary_accuracy: 0.9686\n",
      "Epoch 29/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1008 - binary_accuracy: 0.9689\n",
      "Epoch 30/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1001 - binary_accuracy: 0.9691\n",
      "Epoch 31/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0994 - binary_accuracy: 0.9693\n",
      "Epoch 32/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0988 - binary_accuracy: 0.9695\n",
      "Epoch 33/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0982 - binary_accuracy: 0.9696\n",
      "Epoch 34/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0976 - binary_accuracy: 0.9698\n",
      "Epoch 35/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0970 - binary_accuracy: 0.9700\n",
      "Epoch 36/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0965 - binary_accuracy: 0.9702\n",
      "Epoch 37/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0960 - binary_accuracy: 0.9703\n",
      "Epoch 38/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0955 - binary_accuracy: 0.9705\n",
      "Epoch 39/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0951 - binary_accuracy: 0.9706\n",
      "Epoch 40/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0946 - binary_accuracy: 0.9707\n",
      "Epoch 41/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0942 - binary_accuracy: 0.9708\n",
      "Epoch 42/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0938 - binary_accuracy: 0.9710\n",
      "Epoch 43/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0934 - binary_accuracy: 0.9711\n",
      "Epoch 44/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0930 - binary_accuracy: 0.9711\n",
      "Epoch 45/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0926 - binary_accuracy: 0.9712\n",
      "Epoch 46/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0922 - binary_accuracy: 0.9713\n",
      "Epoch 47/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0919 - binary_accuracy: 0.9714\n",
      "Epoch 48/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0915 - binary_accuracy: 0.9715\n",
      "Epoch 49/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0912 - binary_accuracy: 0.9716\n",
      "Epoch 50/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0909 - binary_accuracy: 0.9717\n",
      "Epoch 51/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0906 - binary_accuracy: 0.9718\n",
      "Epoch 52/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0903 - binary_accuracy: 0.9719\n",
      "Epoch 53/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0900 - binary_accuracy: 0.9720\n",
      "Epoch 54/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0897 - binary_accuracy: 0.9720\n",
      "Epoch 55/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0894 - binary_accuracy: 0.9721\n",
      "Epoch 56/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0892 - binary_accuracy: 0.9722\n",
      "Epoch 57/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0889 - binary_accuracy: 0.9723\n",
      "Epoch 58/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0886 - binary_accuracy: 0.9724\n",
      "Epoch 59/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0884 - binary_accuracy: 0.9725\n",
      "Epoch 60/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0881 - binary_accuracy: 0.9725\n",
      "Epoch 61/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0879 - binary_accuracy: 0.9726\n",
      "Epoch 62/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0877 - binary_accuracy: 0.9726\n",
      "Epoch 63/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0875 - binary_accuracy: 0.9727\n",
      "Epoch 64/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0872 - binary_accuracy: 0.9728\n",
      "Epoch 65/500\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0870 - binary_accuracy: 0.9728\n",
      "Epoch 66/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0868 - binary_accuracy: 0.9729\n",
      "Epoch 67/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0866 - binary_accuracy: 0.9730\n",
      "Epoch 68/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0864 - binary_accuracy: 0.9730\n",
      "Epoch 69/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0862 - binary_accuracy: 0.9731\n",
      "Epoch 70/500\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0860 - binary_accuracy: 0.9732\n",
      "Epoch 71/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0858 - binary_accuracy: 0.9732\n",
      "Epoch 72/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0856 - binary_accuracy: 0.9733\n",
      "Epoch 73/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0855 - binary_accuracy: 0.9733\n",
      "Epoch 74/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0853 - binary_accuracy: 0.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0851 - binary_accuracy: 0.9734\n",
      "Epoch 76/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0849 - binary_accuracy: 0.9734\n",
      "Epoch 77/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0848 - binary_accuracy: 0.9735\n",
      "Epoch 78/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0846 - binary_accuracy: 0.9736\n",
      "Epoch 79/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0844 - binary_accuracy: 0.9736\n",
      "Epoch 80/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0843 - binary_accuracy: 0.9736\n",
      "Epoch 81/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0841 - binary_accuracy: 0.9737\n",
      "Epoch 82/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0840 - binary_accuracy: 0.9738\n",
      "Epoch 83/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0838 - binary_accuracy: 0.9738\n",
      "Epoch 84/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0837 - binary_accuracy: 0.9739\n",
      "Epoch 85/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0835 - binary_accuracy: 0.9739\n",
      "Epoch 86/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0834 - binary_accuracy: 0.9739\n",
      "Epoch 87/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0832 - binary_accuracy: 0.9740\n",
      "Epoch 88/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0831 - binary_accuracy: 0.9740\n",
      "Epoch 89/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0830 - binary_accuracy: 0.9741\n",
      "Epoch 90/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0828 - binary_accuracy: 0.9741\n",
      "Epoch 91/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0827 - binary_accuracy: 0.9742\n",
      "Epoch 92/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0826 - binary_accuracy: 0.9742\n",
      "Epoch 93/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0824 - binary_accuracy: 0.9743\n",
      "Epoch 94/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0823 - binary_accuracy: 0.9743\n",
      "Epoch 95/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0822 - binary_accuracy: 0.9743\n",
      "Epoch 96/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0821 - binary_accuracy: 0.9744\n",
      "Epoch 97/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0820 - binary_accuracy: 0.9744\n",
      "Epoch 98/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0818 - binary_accuracy: 0.9745\n",
      "Epoch 99/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0817 - binary_accuracy: 0.9745\n",
      "Epoch 100/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0816 - binary_accuracy: 0.9746\n",
      "Epoch 101/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0815 - binary_accuracy: 0.9746\n",
      "Epoch 102/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0814 - binary_accuracy: 0.9747\n",
      "Epoch 103/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0813 - binary_accuracy: 0.9747\n",
      "Epoch 104/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0812 - binary_accuracy: 0.9747\n",
      "Epoch 105/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0811 - binary_accuracy: 0.9747\n",
      "Epoch 106/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0810 - binary_accuracy: 0.9748\n",
      "Epoch 107/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0808 - binary_accuracy: 0.9748\n",
      "Epoch 108/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0807 - binary_accuracy: 0.9748\n",
      "Epoch 109/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0806 - binary_accuracy: 0.9749\n",
      "Epoch 110/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0805 - binary_accuracy: 0.9749\n",
      "Epoch 111/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0804 - binary_accuracy: 0.9749\n",
      "Epoch 112/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0804 - binary_accuracy: 0.9749\n",
      "Epoch 113/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0803 - binary_accuracy: 0.9750\n",
      "Epoch 114/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0802 - binary_accuracy: 0.9750\n",
      "Epoch 115/500\n",
      "1200/1200 [==============================] - 5s 5ms/step - loss: 0.0801 - binary_accuracy: 0.9750\n",
      "Epoch 116/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0800 - binary_accuracy: 0.9750\n",
      "Epoch 117/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0799 - binary_accuracy: 0.9751\n",
      "Epoch 118/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0798 - binary_accuracy: 0.9751\n",
      "Epoch 119/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0797 - binary_accuracy: 0.9751\n",
      "Epoch 120/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0796 - binary_accuracy: 0.9752\n",
      "Epoch 121/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0795 - binary_accuracy: 0.9752\n",
      "Epoch 122/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0794 - binary_accuracy: 0.9752\n",
      "Epoch 123/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0794 - binary_accuracy: 0.9752\n",
      "Epoch 124/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0793 - binary_accuracy: 0.9752\n",
      "Epoch 125/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0792 - binary_accuracy: 0.9753\n",
      "Epoch 126/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0791 - binary_accuracy: 0.9753\n",
      "Epoch 127/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0790 - binary_accuracy: 0.9753\n",
      "Epoch 128/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0789 - binary_accuracy: 0.9753\n",
      "Epoch 129/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0789 - binary_accuracy: 0.9754\n",
      "Epoch 130/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0788 - binary_accuracy: 0.9754\n",
      "Epoch 131/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0787 - binary_accuracy: 0.9754\n",
      "Epoch 132/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0786 - binary_accuracy: 0.9755\n",
      "Epoch 133/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0786 - binary_accuracy: 0.9755\n",
      "Epoch 134/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0785 - binary_accuracy: 0.9755\n",
      "Epoch 135/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0784 - binary_accuracy: 0.9755\n",
      "Epoch 136/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0783 - binary_accuracy: 0.9756\n",
      "Epoch 137/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0783 - binary_accuracy: 0.9756\n",
      "Epoch 138/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0782 - binary_accuracy: 0.9756\n",
      "Epoch 139/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0781 - binary_accuracy: 0.9756\n",
      "Epoch 140/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0780 - binary_accuracy: 0.9756\n",
      "Epoch 141/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0780 - binary_accuracy: 0.9757\n",
      "Epoch 142/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0779 - binary_accuracy: 0.9757\n",
      "Epoch 143/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0778 - binary_accuracy: 0.9757\n",
      "Epoch 144/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0778 - binary_accuracy: 0.9757\n",
      "Epoch 145/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0777 - binary_accuracy: 0.9757\n",
      "Epoch 146/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0776 - binary_accuracy: 0.9758\n",
      "Epoch 147/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0776 - binary_accuracy: 0.9758\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0775 - binary_accuracy: 0.9758\n",
      "Epoch 149/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0774 - binary_accuracy: 0.9758\n",
      "Epoch 150/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0774 - binary_accuracy: 0.9759\n",
      "Epoch 151/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0773 - binary_accuracy: 0.9759\n",
      "Epoch 152/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0773 - binary_accuracy: 0.9759\n",
      "Epoch 153/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0772 - binary_accuracy: 0.9759\n",
      "Epoch 154/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0771 - binary_accuracy: 0.9759\n",
      "Epoch 155/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0771 - binary_accuracy: 0.9759\n",
      "Epoch 156/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0770 - binary_accuracy: 0.9760\n",
      "Epoch 157/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0770 - binary_accuracy: 0.9760\n",
      "Epoch 158/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0769 - binary_accuracy: 0.9760\n",
      "Epoch 159/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0768 - binary_accuracy: 0.9760\n",
      "Epoch 160/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0768 - binary_accuracy: 0.9761\n",
      "Epoch 161/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0767 - binary_accuracy: 0.9761\n",
      "Epoch 162/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0767 - binary_accuracy: 0.9761\n",
      "Epoch 163/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0766 - binary_accuracy: 0.9761\n",
      "Epoch 164/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0765 - binary_accuracy: 0.9761\n",
      "Epoch 165/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0765 - binary_accuracy: 0.9761\n",
      "Epoch 166/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0764 - binary_accuracy: 0.9762\n",
      "Epoch 167/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0764 - binary_accuracy: 0.9762\n",
      "Epoch 168/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0763 - binary_accuracy: 0.9762\n",
      "Epoch 169/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0763 - binary_accuracy: 0.9762\n",
      "Epoch 170/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0762 - binary_accuracy: 0.9762\n",
      "Epoch 171/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0762 - binary_accuracy: 0.9763\n",
      "Epoch 172/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0761 - binary_accuracy: 0.9763\n",
      "Epoch 173/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0761 - binary_accuracy: 0.9763\n",
      "Epoch 174/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0760 - binary_accuracy: 0.9763\n",
      "Epoch 175/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0760 - binary_accuracy: 0.9763\n",
      "Epoch 176/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0759 - binary_accuracy: 0.9763\n",
      "Epoch 177/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0759 - binary_accuracy: 0.9763\n",
      "Epoch 178/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0758 - binary_accuracy: 0.9764\n",
      "Epoch 179/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0758 - binary_accuracy: 0.9764\n",
      "Epoch 180/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0757 - binary_accuracy: 0.9764\n",
      "Epoch 181/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0757 - binary_accuracy: 0.9764\n",
      "Epoch 182/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0756 - binary_accuracy: 0.9764\n",
      "Epoch 183/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0756 - binary_accuracy: 0.9764\n",
      "Epoch 184/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0755 - binary_accuracy: 0.9764\n",
      "Epoch 185/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0755 - binary_accuracy: 0.9765\n",
      "Epoch 186/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0754 - binary_accuracy: 0.9765\n",
      "Epoch 187/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0754 - binary_accuracy: 0.9765\n",
      "Epoch 188/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0753 - binary_accuracy: 0.9765\n",
      "Epoch 189/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0753 - binary_accuracy: 0.9765\n",
      "Epoch 190/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0752 - binary_accuracy: 0.9765\n",
      "Epoch 191/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0752 - binary_accuracy: 0.9765\n",
      "Epoch 192/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0752 - binary_accuracy: 0.9766\n",
      "Epoch 193/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0751 - binary_accuracy: 0.9766\n",
      "Epoch 194/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0751 - binary_accuracy: 0.9766\n",
      "Epoch 195/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0750 - binary_accuracy: 0.9766\n",
      "Epoch 196/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0750 - binary_accuracy: 0.9766\n",
      "Epoch 197/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0749 - binary_accuracy: 0.9766\n",
      "Epoch 198/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0749 - binary_accuracy: 0.9766\n",
      "Epoch 199/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0748 - binary_accuracy: 0.9766\n",
      "Epoch 200/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0748 - binary_accuracy: 0.9766\n",
      "Epoch 201/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0748 - binary_accuracy: 0.9767\n",
      "Epoch 202/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0747 - binary_accuracy: 0.9767\n",
      "Epoch 203/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0747 - binary_accuracy: 0.9767\n",
      "Epoch 204/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0746 - binary_accuracy: 0.9767\n",
      "Epoch 205/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0746 - binary_accuracy: 0.9767\n",
      "Epoch 206/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0746 - binary_accuracy: 0.9767\n",
      "Epoch 207/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0745 - binary_accuracy: 0.9767\n",
      "Epoch 208/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0745 - binary_accuracy: 0.9767\n",
      "Epoch 209/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0744 - binary_accuracy: 0.9767\n",
      "Epoch 210/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0744 - binary_accuracy: 0.9767\n",
      "Epoch 211/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0744 - binary_accuracy: 0.9768\n",
      "Epoch 212/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0743 - binary_accuracy: 0.9768\n",
      "Epoch 213/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0743 - binary_accuracy: 0.9768\n",
      "Epoch 214/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0742 - binary_accuracy: 0.9768\n",
      "Epoch 215/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0742 - binary_accuracy: 0.9768\n",
      "Epoch 216/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0742 - binary_accuracy: 0.9768\n",
      "Epoch 217/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0741 - binary_accuracy: 0.9768\n",
      "Epoch 218/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0741 - binary_accuracy: 0.9769\n",
      "Epoch 219/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0741 - binary_accuracy: 0.9768\n",
      "Epoch 220/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0740 - binary_accuracy: 0.9769\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0740 - binary_accuracy: 0.9769\n",
      "Epoch 222/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0739 - binary_accuracy: 0.9769\n",
      "Epoch 223/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0739 - binary_accuracy: 0.9769\n",
      "Epoch 224/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0739 - binary_accuracy: 0.9769\n",
      "Epoch 225/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0738 - binary_accuracy: 0.9769\n",
      "Epoch 226/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0738 - binary_accuracy: 0.9769\n",
      "Epoch 227/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0738 - binary_accuracy: 0.9769\n",
      "Epoch 228/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0737 - binary_accuracy: 0.9769\n",
      "Epoch 229/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0737 - binary_accuracy: 0.9770\n",
      "Epoch 230/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0737 - binary_accuracy: 0.9770\n",
      "Epoch 231/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0736 - binary_accuracy: 0.9770\n",
      "Epoch 232/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0736 - binary_accuracy: 0.9770\n",
      "Epoch 233/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0736 - binary_accuracy: 0.9770\n",
      "Epoch 234/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0735 - binary_accuracy: 0.9770\n",
      "Epoch 235/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0735 - binary_accuracy: 0.9770\n",
      "Epoch 236/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0735 - binary_accuracy: 0.9770\n",
      "Epoch 237/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0734 - binary_accuracy: 0.9770\n",
      "Epoch 238/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0734 - binary_accuracy: 0.9770\n",
      "Epoch 239/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0734 - binary_accuracy: 0.9770\n",
      "Epoch 240/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0733 - binary_accuracy: 0.9771\n",
      "Epoch 241/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0733 - binary_accuracy: 0.9771\n",
      "Epoch 242/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0733 - binary_accuracy: 0.9771\n",
      "Epoch 243/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0732 - binary_accuracy: 0.9771\n",
      "Epoch 244/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0732 - binary_accuracy: 0.9771\n",
      "Epoch 245/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0732 - binary_accuracy: 0.9771\n",
      "Epoch 246/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0731 - binary_accuracy: 0.9771\n",
      "Epoch 247/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0731 - binary_accuracy: 0.9771\n",
      "Epoch 248/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0731 - binary_accuracy: 0.9771\n",
      "Epoch 249/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0730 - binary_accuracy: 0.9771\n",
      "Epoch 250/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0730 - binary_accuracy: 0.9772\n",
      "Epoch 251/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0730 - binary_accuracy: 0.9772\n",
      "Epoch 252/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0730 - binary_accuracy: 0.9772\n",
      "Epoch 253/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0729 - binary_accuracy: 0.9772\n",
      "Epoch 254/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0729 - binary_accuracy: 0.9772\n",
      "Epoch 255/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0729 - binary_accuracy: 0.9772\n",
      "Epoch 256/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0728 - binary_accuracy: 0.9772\n",
      "Epoch 257/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0728 - binary_accuracy: 0.9772\n",
      "Epoch 258/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0728 - binary_accuracy: 0.9772\n",
      "Epoch 259/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0728 - binary_accuracy: 0.9772\n",
      "Epoch 260/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0727 - binary_accuracy: 0.9773\n",
      "Epoch 261/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0727 - binary_accuracy: 0.9773\n",
      "Epoch 262/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0727 - binary_accuracy: 0.9773\n",
      "Epoch 263/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9773\n",
      "Epoch 264/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9773\n",
      "Epoch 265/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9773\n",
      "Epoch 266/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9773\n",
      "Epoch 267/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0725 - binary_accuracy: 0.9773\n",
      "Epoch 268/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0725 - binary_accuracy: 0.9773\n",
      "Epoch 269/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0725 - binary_accuracy: 0.9773\n",
      "Epoch 270/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0724 - binary_accuracy: 0.9773\n",
      "Epoch 271/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0724 - binary_accuracy: 0.9774\n",
      "Epoch 272/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0724 - binary_accuracy: 0.9774\n",
      "Epoch 273/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0724 - binary_accuracy: 0.9773\n",
      "Epoch 274/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0723 - binary_accuracy: 0.9774\n",
      "Epoch 275/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0723 - binary_accuracy: 0.9774\n",
      "Epoch 276/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0723 - binary_accuracy: 0.9774\n",
      "Epoch 277/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0723 - binary_accuracy: 0.9774\n",
      "Epoch 278/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0722 - binary_accuracy: 0.9774\n",
      "Epoch 279/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0722 - binary_accuracy: 0.9774\n",
      "Epoch 280/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0722 - binary_accuracy: 0.9774\n",
      "Epoch 281/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0722 - binary_accuracy: 0.9774\n",
      "Epoch 282/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0721 - binary_accuracy: 0.9774\n",
      "Epoch 283/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0721 - binary_accuracy: 0.9774\n",
      "Epoch 284/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0721 - binary_accuracy: 0.9774\n",
      "Epoch 285/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0721 - binary_accuracy: 0.9774\n",
      "Epoch 286/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0720 - binary_accuracy: 0.9774\n",
      "Epoch 287/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0720 - binary_accuracy: 0.9775\n",
      "Epoch 288/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0720 - binary_accuracy: 0.9775\n",
      "Epoch 289/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0720 - binary_accuracy: 0.9775\n",
      "Epoch 290/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0719 - binary_accuracy: 0.9775\n",
      "Epoch 291/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0719 - binary_accuracy: 0.9775\n",
      "Epoch 292/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0719 - binary_accuracy: 0.9775\n",
      "Epoch 293/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0719 - binary_accuracy: 0.9775\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0718 - binary_accuracy: 0.9775\n",
      "Epoch 295/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0718 - binary_accuracy: 0.9775\n",
      "Epoch 296/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0718 - binary_accuracy: 0.9775\n",
      "Epoch 297/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0718 - binary_accuracy: 0.9776\n",
      "Epoch 298/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0717 - binary_accuracy: 0.9776\n",
      "Epoch 299/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0717 - binary_accuracy: 0.9775\n",
      "Epoch 300/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0717 - binary_accuracy: 0.9776\n",
      "Epoch 301/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0717 - binary_accuracy: 0.9776\n",
      "Epoch 302/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0716 - binary_accuracy: 0.9776\n",
      "Epoch 303/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0716 - binary_accuracy: 0.9776\n",
      "Epoch 304/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0716 - binary_accuracy: 0.9776\n",
      "Epoch 305/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0716 - binary_accuracy: 0.9776\n",
      "Epoch 306/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0715 - binary_accuracy: 0.9776\n",
      "Epoch 307/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0715 - binary_accuracy: 0.9776\n",
      "Epoch 308/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0715 - binary_accuracy: 0.9776\n",
      "Epoch 309/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0715 - binary_accuracy: 0.9776\n",
      "Epoch 310/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0715 - binary_accuracy: 0.9776\n",
      "Epoch 311/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0714 - binary_accuracy: 0.9776\n",
      "Epoch 312/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0714 - binary_accuracy: 0.9776\n",
      "Epoch 313/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0714 - binary_accuracy: 0.9777\n",
      "Epoch 314/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0714 - binary_accuracy: 0.9777\n",
      "Epoch 315/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0713 - binary_accuracy: 0.9777\n",
      "Epoch 316/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0713 - binary_accuracy: 0.9777\n",
      "Epoch 317/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0713 - binary_accuracy: 0.9777\n",
      "Epoch 318/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0713 - binary_accuracy: 0.9777\n",
      "Epoch 319/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0713 - binary_accuracy: 0.9777\n",
      "Epoch 320/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9777\n",
      "Epoch 321/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9777\n",
      "Epoch 322/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9777\n",
      "Epoch 323/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9778\n",
      "Epoch 324/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9778\n",
      "Epoch 325/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0711 - binary_accuracy: 0.9778\n",
      "Epoch 326/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0711 - binary_accuracy: 0.9778\n",
      "Epoch 327/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0711 - binary_accuracy: 0.9778\n",
      "Epoch 328/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0711 - binary_accuracy: 0.9778\n",
      "Epoch 329/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0711 - binary_accuracy: 0.9778\n",
      "Epoch 330/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0710 - binary_accuracy: 0.9778\n",
      "Epoch 331/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0710 - binary_accuracy: 0.9778\n",
      "Epoch 332/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0710 - binary_accuracy: 0.9778\n",
      "Epoch 333/500\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0710 - binary_accuracy: 0.9778\n",
      "Epoch 334/500\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0710 - binary_accuracy: 0.9778\n",
      "Epoch 335/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0709 - binary_accuracy: 0.9778\n",
      "Epoch 336/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0709 - binary_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0709 - binary_accuracy: 0.9778\n",
      "Epoch 338/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0709 - binary_accuracy: 0.9778\n",
      "Epoch 339/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0709 - binary_accuracy: 0.9778\n",
      "Epoch 340/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0708 - binary_accuracy: 0.9779\n",
      "Epoch 341/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0708 - binary_accuracy: 0.9779\n",
      "Epoch 342/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0708 - binary_accuracy: 0.9779\n",
      "Epoch 343/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0708 - binary_accuracy: 0.9779\n",
      "Epoch 344/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0708 - binary_accuracy: 0.9779\n",
      "Epoch 345/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0707 - binary_accuracy: 0.9779\n",
      "Epoch 346/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0707 - binary_accuracy: 0.9779\n",
      "Epoch 347/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0707 - binary_accuracy: 0.9779\n",
      "Epoch 348/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0707 - binary_accuracy: 0.9779\n",
      "Epoch 349/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0707 - binary_accuracy: 0.9779\n",
      "Epoch 350/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 351/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 352/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 353/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 354/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 355/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0706 - binary_accuracy: 0.9779\n",
      "Epoch 356/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0705 - binary_accuracy: 0.9779\n",
      "Epoch 357/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0705 - binary_accuracy: 0.9779\n",
      "Epoch 358/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0705 - binary_accuracy: 0.9779\n",
      "Epoch 359/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0705 - binary_accuracy: 0.9779\n",
      "Epoch 360/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0705 - binary_accuracy: 0.9779\n",
      "Epoch 361/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9780\n",
      "Epoch 362/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9780\n",
      "Epoch 363/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9779\n",
      "Epoch 364/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9779\n",
      "Epoch 365/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9780\n",
      "Epoch 366/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0704 - binary_accuracy: 0.9780\n",
      "Epoch 367/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 368/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 369/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 370/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 371/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 372/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0703 - binary_accuracy: 0.9780\n",
      "Epoch 373/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 374/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 375/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 376/500\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 377/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 378/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 379/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 380/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 381/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 382/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 383/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 384/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0701 - binary_accuracy: 0.9780\n",
      "Epoch 385/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0700 - binary_accuracy: 0.9780\n",
      "Epoch 386/500\n",
      "1200/1200 [==============================] - 5s 5ms/step - loss: 0.0700 - binary_accuracy: 0.9781\n",
      "Epoch 387/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0700 - binary_accuracy: 0.9781\n",
      "Epoch 388/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0700 - binary_accuracy: 0.9781\n",
      "Epoch 389/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0700 - binary_accuracy: 0.9781\n",
      "Epoch 390/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0700 - binary_accuracy: 0.9781\n",
      "Epoch 391/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 392/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 393/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 394/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 395/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 396/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0699 - binary_accuracy: 0.9781\n",
      "Epoch 397/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 398/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 399/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 400/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 401/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 402/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 403/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 404/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9781\n",
      "Epoch 405/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9781\n",
      "Epoch 406/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9781\n",
      "Epoch 407/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9782\n",
      "Epoch 408/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0697 - binary_accuracy: 0.9782\n",
      "Epoch 409/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9782\n",
      "Epoch 410/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0697 - binary_accuracy: 0.9782\n",
      "Epoch 411/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 412/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 413/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 414/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 415/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 416/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 417/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0696 - binary_accuracy: 0.9782\n",
      "Epoch 418/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 419/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 420/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 421/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 422/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 423/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9783\n",
      "Epoch 424/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0695 - binary_accuracy: 0.9782\n",
      "Epoch 425/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9782\n",
      "Epoch 426/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9782\n",
      "Epoch 427/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9783\n",
      "Epoch 428/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9783\n",
      "Epoch 429/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9783\n",
      "Epoch 430/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9783\n",
      "Epoch 431/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0694 - binary_accuracy: 0.9783\n",
      "Epoch 432/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 433/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 434/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 435/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 436/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 437/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 438/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 439/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 441/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 442/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 443/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 444/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 445/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 446/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0692 - binary_accuracy: 0.9783\n",
      "Epoch 447/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 448/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 449/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 450/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 451/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 452/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 453/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 454/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0691 - binary_accuracy: 0.9783\n",
      "Epoch 455/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 456/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 457/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 458/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 459/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9784\n",
      "Epoch 460/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 461/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 462/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0690 - binary_accuracy: 0.9783\n",
      "Epoch 463/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9783\n",
      "Epoch 464/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 465/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9783\n",
      "Epoch 466/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 467/500\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 468/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 469/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 470/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0689 - binary_accuracy: 0.9784\n",
      "Epoch 471/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 472/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 473/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 474/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 475/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 476/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 477/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 478/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0688 - binary_accuracy: 0.9784\n",
      "Epoch 479/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 480/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 481/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 482/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 483/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 484/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 485/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 486/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 487/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0687 - binary_accuracy: 0.9784\n",
      "Epoch 488/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 489/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 490/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 491/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9785\n",
      "Epoch 492/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 493/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 494/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9785\n",
      "Epoch 495/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9785\n",
      "Epoch 496/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0686 - binary_accuracy: 0.9784\n",
      "Epoch 497/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0685 - binary_accuracy: 0.9785\n",
      "Epoch 498/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0685 - binary_accuracy: 0.9785\n",
      "Epoch 499/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0685 - binary_accuracy: 0.9785\n",
      "Epoch 500/500\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0685 - binary_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15ff880a0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encontré en internet que binarycrossentropy era útil para clasificar\n",
    "#Leí también que sdg encontraba optimos para varios problemas.\n",
    "\n",
    "perceptron.compile(loss='BinaryCrossentropy', optimizer = 'sgd',metrics=['binary_accuracy'])\n",
    "perceptron.fit(x_train, y_train,epochs=500,batch_size=50,shuffle=True,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0665 - binary_accuracy: 0.9797\n",
      "313/313 [==============================] - 0s 780us/step\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0665 - binary_accuracy: 0.9797\n",
      "\n",
      "Test accuracy general: 98.0%\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2101 - binary_accuracy: 0.9980\n",
      "\n",
      "Test accuracy para solo ceros: 99.8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAdemás, verifique el número de porcentaje de puntos que fueron clasificados como 0 pero no eran 0\\n Este número sería 1- acurracy obtenido\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplique el modelo a los datos de test y verifique que tan bien clasificó los números.\n",
    "\n",
    "#Evaluating the model\n",
    "perceptron.evaluate(x_test,y_test)\n",
    "results=perceptron.predict(x_test,verbose=1)\n",
    "#¿Cual es el accuracy general?\n",
    "\n",
    "loss, acc = perceptron.evaluate(x_test, y_test, batch_size=50)\n",
    "print(\"\\nTest accuracy general: %.1f%%\" % (100.0 * acc))\n",
    "\n",
    "#¿Qué tan bien clasificó un número particular, por ejemplo 0?\n",
    "#Para esto, determine el porcentaje de los números que eran 0 y los clasificaron como 0.\n",
    "\n",
    "cero_target = np.array([0,0,0,0,0,0,0,1,0,0]).astype('float32')\n",
    "# NO ME FUNCIONO : (  only_ceros = np.where(np.array_equal(y_test,cero_target))\n",
    "\n",
    "#No se me ocurrió algo más eficente que esto \n",
    "\n",
    "ceros_array_x = np.zeros(((10000, 784)))\n",
    "ceros_array_y = np.zeros((10000, 10))\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    if np.array_equal(y_test[i],cero_target):\n",
    "        ceros_array_x[i] = x_test[i]\n",
    "        ceros_array_y[i]= y_test[i]\n",
    "        \n",
    "loss, acc = perceptron.evaluate(ceros_array_x,ceros_array_y, batch_size=50)\n",
    "print(\"\\nTest accuracy para solo ceros: %.1f%%\" % (100.0 * acc))\n",
    "\n",
    "\"\"\"\n",
    "Además, verifique el número de porcentaje de puntos que fueron clasificados como 0 pero no eran 0\n",
    " Este número sería 1- acurracy obtenido\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
